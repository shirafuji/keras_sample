# -*- coding: utf-8 -*-
"""mnist_sample.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/135jPfrRxPucTC2fBwEUwBjrVwRs-mzVy

#mnist_sample
google colaboratoryを利用してmnistを学習するsample codeです。
"""

!apt-get install lshw

!lshw

"""GPUを認識しているかの確認"""

import tensorflow as tf
tf.test.gpu_device_name()

# 使用するライブラリのインポート
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, InputLayer
from keras.optimizers import RMSprop

import matplotlib.pyplot as plt

"""## シンプルなニューラルネットワーク"""

# mnistデータの読み込み(x:訓練, y:正解)
(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

# 入力データの加工
x_train = x_train.reshape(60000, 784)
x_test = x_test.reshape(10000, 784)

# 文字列データをfloat型に変換
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
# 0~255までの数値を0~1に変換
x_train /= 255
x_test /= 255

# 正解データの加工(1と0を用いた配列に変換)
y_train = keras.utils.to_categorical(y_train, 10)
y_test  = keras.utils.to_categorical(y_test, 10)

print("x_train.shape(学習用の画像データ) : ", x_train.shape)
print("y_train_shape(学習用の正解データ) : ", y_train.shape)
print("x_test.shape(検証用の画像データ) : ", x_test.shape)
print("y_test.shape(検証用の正解データ) : ", y_test.shape)

# モデルの構築
model = Sequential()
model.add(InputLayer(input_shape=(784,)))
model.add(Dense(10, activation='softmax'))

# モデルをコンパイルする
model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

# 学習
epochs = 20
batch_size = 128
history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))

# 学習結果
score = model.evaluate(x_test, y_test, verbose=1)
print()
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# 学習経過の可視化
loss     = history.history['loss']
val_loss = history.history['val_loss']

nb_epoch = len(loss)
plt.plot(range(nb_epoch), loss,     marker='.', label='loss')
plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')
plt.legend(loc='best', fontsize=10)
plt.grid()
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()

"""## 畳み込みニューラルネットワーク"""

import tensorflow as tf
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, InputLayer, Conv2D, MaxPooling2D, Flatten
from keras.optimizers import RMSprop

import matplotlib.pyplot as plt

# データの読み込み
(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

# 入力データの加工

## データを float 型に変換
x_train = x_train.astype('float32')
x_test  = x_test.astype('float32')
## 正規化
x_train = x_train / 255
x_test = x_test / 255
## reshape(ミニバッチサイズ、横幅、縦幅、チャネル数に)
x_train = x_train.reshape((-1, 28, 28, 1))
x_test = x_test.reshape((-1, 28, 28, 1))


## 正解データの加工
y_train = keras.utils.to_categorical(y_train, 10)
y_test = keras.utils.to_categorical(y_test, 10)
y_train = y_train.reshape((-1, 10))
y_test = y_test.reshape((-1, 10))

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

# モデルの構築

model = Sequential()

## 畳み込み層
model.add(
    Conv2D(
        filters=32,
        input_shape=(28, 28, 1),
        kernel_size=(3, 3),
        strides=(1, 1),
        padding='same',
        activation='relu'
    )
)
## プーリング層
model.add(MaxPooling2D(pool_size=(2,2)))
## ドロップアウト層
model.add(Dropout(0.25))
## Flattenレイヤー
model.add(Flatten())
## 全結合層
model.add(Dense(units=512, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))
# モデルをコンパイルする
model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

# 学習
epochs = 20
batch_size = 128
history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))

# モデルの評価
score = model.evaluate(x_test, y_test, verbose=1)
print()
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# 学習経過の可視化
loss     = history.history['loss']
val_loss = history.history['val_loss']

nb_epoch = len(loss)
plt.plot(range(nb_epoch), loss,     marker='.', label='loss')
plt.plot(range(nb_epoch), val_loss, marker='.', label='val_loss')
plt.legend(loc='best', fontsize=10)
plt.grid()
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()